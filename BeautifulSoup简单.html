<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
</head>
<body>
  <div class="container">
      下面的一段HTML代码将作为例子被多次用到.这是 爱丽丝梦游仙境的 的一段内容(以后内容中简称为 爱丽丝 的文档):
      <code>html_doc = """
          &lt;html&gt;
          &lt;head&gt;
          &lt;title&gt;
          The Dormouse's story
          &lt;/title&gt;
          &lt;/head&gt;
          &lt;body&gt;
          &lt;p class="title"&gt;
          &lt;b&gt;
          The Dormouse's story
          &lt;/b&gt;
          &lt;/p&gt;
          &lt;p class="story"&gt;
          Once upon a time there were three little sisters; and their names were
          &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;
          Elsie
          &lt;/a&gt;
          ,
          &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;
          Lacie
          &lt;/a&gt;
          and
          &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;
          Tillie
          &lt;/a&gt;
          ;
          and they lived at the bottom of a well.
          &lt;/p&gt;
          &lt;p class="story"&gt;
          ...
          &lt;/p&gt;
          """</code>
      使用BeautifulSoup解析这段代码,能够得到一个 BeautifulSoup 的对象,并能按照标准的缩进格式的结构输出:
      <code>from bs4 import BeautifulSoup
          soup = BeautifulSoup(html_doc, 'html.parser')

          print(<span class="ibk">soup.prettify()</span>)
          #
          &lt;html&gt;
          #
          &lt;head&gt;
          #
          &lt;title&gt;
          #    The Dormouse's story
          #
          &lt;/title&gt;
          #
          &lt;/head&gt;
          #
          &lt;body&gt;
          #
          &lt;p class="title"&gt;
          #
          &lt;b&gt;
          #     The Dormouse's story
          #
          &lt;/b&gt;
          #
          &lt;/p&gt;
          #
          &lt;p class="story"&gt;
          #    Once upon a time there were three little sisters; and their names were
          #
          &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;
          #     Elsie
          #
          &lt;/a&gt;
          #    ,
          #
          &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;
          #     Lacie
          #
          &lt;/a&gt;
          #    and
          #
          &lt;a class="sister" href="http://example.com/tillie" id="link2"&gt;
          #     Tillie
          #
          &lt;/a&gt;
          #    ; and they lived at the bottom of a well.
          #
          &lt;/p&gt;
          #
          &lt;p class="story"&gt;
          #    ...
          #
          &lt;/p&gt;
          #
          &lt;/body&gt;
          #
          &lt;/html&gt;</code>
      几个简单的浏览结构化数据的方法:
      <code>soup.<span class="ibk">title</span>
          #
          &lt;title&gt;
          The Dormouse's story
          &lt;/title&gt;
          soup.<span class="ibk">title.name</span>
          # u'title'

          soup.<span class="ibk">title.string</span>
          # u'The Dormouse's story'

          soup.<span class="ibk">title.parent.name</span>  # head&gt;title
          # u'head'

          soup.<span class="ibk">p</span>
          #
          &lt;p class="title"&gt;
          &lt;b&gt;
          The Dormouse's story
          &lt;/b&gt;
          &lt;/p&gt;
          soup.<span class="ibk">p['class'] </span># class="title"
          # u'title'

          soup.<span class="ibk">a</span>
          #
          &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;
          Elsie
          &lt;/a&gt;
          soup.<span class="ibk">find_all('a')</span>
          # [
          &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;
          Elsie
          &lt;/a&gt;
          ,
          #
          &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;
          Lacie
          &lt;/a&gt;
          ,
          #
          &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;
          Tillie
          &lt;/a&gt;
          ]

          soup.{{find(id="link3")}} # id="link3"
          #
          &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;
          Tillie
          &lt;/a&gt;</code>

      从文档中找到所有
      &lt;a&gt;
      标签的链接:
      <code>for link in <span class="ibk">soup.find_all('a')</span>:
          print(link.get('href'))
          # http://example.com/elsie
          # http://example.com/lacie
          # http://example.com/tillie</code>
      从文档中获取所有文字内容:
      <code>print(soup.<span class="ibk">get_text()</span>)
          # The Dormouse's story
          #
          # The Dormouse's story
          #
          # Once upon a time there were three little sisters; and their names were
          # Elsie,
          # Lacie and
          # Tillie;
          # and they lived at the bottom of a well.
          #
          # ...</code>


      Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种: Tag , NavigableString , BeautifulSoup , Comment .
      <code>soup = BeautifulSoup('
          &lt;b class="boldest"&gt;
          Extremely bold
          &lt;/b&gt;
          ')
          tag = soup.b
          每个tag都有自己的名字,通过 <span class="ibk">.name</span> 来获取

          如果改变了tag的name,那将影响所有通过当前Beautiful Soup对象生成的HTML文档:
          tag.name = "blockquote"
          tag
          #
          &lt;blockquote class="boldest"&gt;
          Extremely bold
          &lt;/blockquote&gt;</code>
      <code>一个tag可能有很多个属性. tag
          &lt;b class="boldest"&gt;
          有一个 “class” 的属性,值为 “boldest” . tag的属性的操作方法与字典相同:
          <span class="ibk">tag['class']</span>

          也可以直接”点”取属性, 比如: <span class="ibk">.attrs</span> :

          tag的属性可以被添加,删除或修改. tag的属性操作方法与字典一样
          tag['class'] = 'verybold'
          tag['id'] = 1
          tag
          #
          &lt;blockquote class="verybold" id="1"&gt;
          Extremely bold
          &lt;/blockquote&gt;
          del tag['class']
          del tag['id']
          tag
          #
          &lt;blockquote&gt;
          Extremely bold
          &lt;/blockquote&gt;
          tag['class']
          # KeyError: 'class'
          print(tag.get('class'))
          # None</code>

      <code>在Beautiful Soup中多值属性的返回类型是list:
          css_soup = BeautifulSoup('
          &lt;p class="body strikeout"&gt;
          &lt;/p&gt;
          ')
          css_soup.<span class="ibk">p['class']</span>
          # ["body", "strikeout"]

          HTML定义中都没有被定义为多值属性,那么Beautiful Soup会将这个属性作为字符串返回
          id_soup = BeautifulSoup('
          &lt;p id="my id"&gt;
          &lt;/p&gt;
          ')
          id_soup.p['id']
          # 'my id'

          将tag转换成字符串时,多值属性会合并为一个值
          rel_soup.a['rel'] = ['index', 'contents']
          print(rel_soup.p)
          #
          &lt;p&gt;
          Back to the
          &lt;a rel="index contents"&gt;
          homepage
          &lt;/a&gt;
          &lt;/p&gt;
          如果转换的文档是XML格式,那么tag中不包含多值属性
          xml_soup = BeautifulSoup('
          &lt;p class="body strikeout"&gt;
          &lt;/p&gt;
          ', 'xml')
          xml_soup.p['class']
          # u'body strikeout'</code>


      字符串常被包含在tag内.Beautiful Soup用 <span class="ibk">NavigableString</span> 类来包装tag中的字符串:
      <code>tag.string
          # u'Extremely bold'
          type(tag.string)
          #
          &lt;class 'bs4.element.navigablestring'=""&gt;
          通过 <span class="ibk">unicode()</span> 方法可以直接将 NavigableString 对象转换成Unicode字符串:
          unicode_string = unicode(tag.string)
          unicode_string
          # u'Extremely bold'
          type(unicode_string)
          #
          &lt;type 'unicode'=""&gt;
          tag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 <span class="ibk">replace_with()</span> 方法:
          在Beautiful Soup之外使用 NavigableString 对象,需要调用 unicode() 方法,将该对象转换成普通的Unicode字符串,
          tag.string.replace_with("No longer bold")
          tag
          #
          &lt;blockquote&gt;
          No longer bold
          &lt;/blockquote&gt;</code>


      文档的注释部分
      <code>markup = "
          &lt;b&gt;
          &lt;!--Hey, buddy. Want to buy a used parser?--&gt;
          &lt;/b&gt;
          "
          soup = BeautifulSoup(markup)
          comment = soup.b.string
          type(comment)
          #
          &lt;class 'bs4.element.comment'=""&gt;
          Comment 对象是一个特殊类型的 NavigableString 对象:

          comment
          # u'Hey, buddy. Want to buy a used parser'
          但是当它出现在HTML文档中时, Comment 对象会使用特殊的格式输出
          print(soup.b.prettify())
          #
          &lt;b&gt;
          #
          &lt;!--Hey, buddy. Want to buy a used parser?--&gt;
          #
          &lt;/b&gt;</code>

      用CDATA来替代注释的例子:
      <code>from bs4 import CData
          cdata =<span class="ibk"> CData("A CDATA block")</span>
          comment.replace_with(cdata)

          print(soup.b.prettify())
          #
          &lt;b&gt;
          #
          &lt;![CDATA[A CDATA block]]&gt;
          #
          &lt;/b&gt;</code>

      遍历文档树
      <code>要得到所有的
          &lt;a&gt;
          标签
          soup.<span class="ibk">find_all('a')</span>
          .contents 和 .children 属性仅包含tag的直接子节点

          tag的 .contents 属性可以将tag的子节点以列表的方式输出:
          head_tag = soup.head
          head_tag
          #
          &lt;head&gt;
          &lt;title&gt;
          The Dormouse's story
          &lt;/title&gt;
          &lt;/head&gt;
          head_tag.<span class="ibk">contents</span>
          [
          &lt;title&gt;
          The Dormouse's story
          &lt;/title&gt;
          ]

          title_tag = head_tag.contents[0]
          title_tag
          #
          &lt;title&gt;
          The Dormouse's story
          &lt;/title&gt;
          title_tag.contents
          # [u'The Dormouse's story']

          字符串没有 .contents 属性,因为字符串没有子节点:

          通过tag的 .children 生成器,可以对tag的子节点进行循环:
          for child in <span class="ibk">title_tag.children</span>:
          print(child)
          # The Dormouse's story

          .<span class="ibk">descendants</span> 属性可以对所有tag的子孙节点进行递归循环 [5] :

          如果tag中包含多个字符串 [2] ,可以使用 .<span class="ibk">strings</span> 来循环获取:

          输出的字符串中可能包含了很多空格或空行,使用 .<span class="ibk">stripped_strings</span> 可以去除多余空白内容:
          全部是空格的行会被忽略掉,段首和段末的空白会被删除


          通过元素的 .parents 属性可以递归得到元素的所有父辈节点

          ,使用 .<span class="ibk">next_sibling</span> 和 .<span class="ibk">previous_sibling</span> 属性来查询兄弟节点</code>

      <code>实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白. 看看“爱丽丝”文档: 注意顿号和换行符
          &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;
          Elsie
          &lt;/a&gt;
          &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;
          Lacie
          &lt;/a&gt;
          &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;
          Tillie
          &lt;/a&gt;
          如果以为第一个
          &lt;a&gt;
          标签的 .next_sibling 结果是第二个
          &lt;a&gt;
          标签,那就错了,真实结果是第一个
          &lt;a&gt;
          标签和第二个
          &lt;a&gt;
          标签之间的顿号和换行符:

          link = soup.a
          link
          #
          &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;
          Elsie
          &lt;/a&gt;
          link.next_sibling
          # u',\n'

          通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出:
          for sibling in soup.a.next_siblings:
          print(repr(sibling))
          # u',\n'
          #
          &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;
          Lacie
          &lt;/a&gt;
          # u' and\n'F
          #
          &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;
          Tillie
          &lt;/a&gt;
          # u'; and they lived at the bottom of a well.'
          # None

          .next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),结果可能与 .next_sibling 相同,但通常是不一样的.

          通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:</code>

      搜索文档树

      <code>
          soup.find_all('b')
          正则表达式
          for tag in soup.find_all(re.compile("^b")):
          列表
          soup.find_all(["a", "b"])
          True 可以匹配任何值,下面代码查找到所有的tag,

          方法
          返回 True 表示当前元素匹配并且被找到,如果不是则反回 False

          方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True
          soup.find_all(has_class_but_no_id)
          # [
          &lt;p class="title"&gt;
          &lt;b&gt;
          The Dormouse's story
          &lt;/b&gt;
          &lt;/p&gt;
          ,
          #
          &lt;p class="story"&gt;
          Once upon a time there were...
          &lt;/p&gt;
          ,
          #
          &lt;p class="story"&gt;
          ...
          &lt;/p&gt;
          ]

          指定tag
          找出 href 属性不符合指定正则的 a 标签
          def not_lacie(href):
          return href and not re.compile("lacie").search(href)
          soup.find_all(href=not_lacie)
          # [
          &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;
          Elsie
          &lt;/a&gt;
          ,
          #
          &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;
          Tillie
          &lt;/a&gt;
          ]

          过滤出前后都有文字的标签.
          from bs4 import NavigableString
          def surrounded_by_strings(tag):
          return (isinstance(tag.next_element, NavigableString)
          and isinstance(tag.previous_element, NavigableString))

          for tag in soup.find_all(surrounded_by_strings):
          print tag.name
          # p
          # a
          # a
          # a
          # p

          把该参数当作指定名字tag的属性来搜索,如果包含一个名字为 id 的参数,Beautiful Soup会搜索每个tag的”id”属性.
          soup.find_all(id='link2')

          如果传入 href 参数,Beautiful Soup会搜索每个tag的”href”属性:
          soup.find_all(href=re.compile("elsie"))
          # [
          &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;
          Elsie
          &lt;/a&gt;
          ]

          在文档树中查找所有包含 id 属性的tag,无论 id 的值是什么
          soup.find_all(id=True)

          使用多个指定名字的参数可以同时过滤tag的多个属性:
          soup.find_all(href=re.compile("elsie"), id='link1')

          通过 find_all() 方法的 attrs 参数定义一个字典参数来搜索包含特殊属性的tag:
          data_soup.find_all(attrs={"data-foo": "value"})

          通过 class_ 参数搜索有指定CSS类名的tag:
          class_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True :
          soup.find_all("a", class_="sister")

          通过 string 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, string 参数接受 字符串 , 正则表达式 , 列表, True .
          soup.find_all(string="Elsie")

          搜索内容里面包含“Elsie”的
          &lt;a&gt;
          标签
          soup.find_all("a", string="Elsie")

          文档树中有3个tag符合搜索条件,但结果限制返回了2个
          soup.find_all("a", limit=2)

          如果只想搜索tag的直接子节点,可以使用参数 recursive=False .
          soup.html.find_all("title", recursive=False)

          下面两行代码是等价的:
          soup.find_all("a") === soup("a")

          soup.title.find_all(string=True)  === soup.title(string=True)


          soup.head.title 是 tag的名字 方法的简写.这个简写的原理就是多次调用当前tag的 find() 方法:
          soup.head.title
          #
          &lt;title&gt;
          The Dormouse's story
          &lt;/title&gt;
          soup.find("head").find("title")
          #
          &lt;title&gt;
          The Dormouse's story
          &lt;/title&gt;
          find_parents() 和 find_parent()
          find_next_siblings() 和 find_next_sibling()
          find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:
          find_all_next() 和 find_next()           - 通过 .next_elements 属性对当前tag的之后的 [5] tag和字符串进行迭
          find_all_previous() 和 find_previous()    - 通过 .previous_elements 属性对当前节点前面 [5] 的tag和字符串进行迭代,

          .select() 方法中传入字符串参数, 即可使用CSS选择器的语法找到tag:
          找到某个tag标签下的直接子标签 soup.select("p &gt; a")
          找到兄弟节点标签:
          soup.select("#link1 ~ .sister")
          soup.select("#link1 + .sister")

          返回查找到的元素的第一个
          soup.select_one(".sister")</code>

      修改文档树
      <code>

          soup = BeautifulSoup('
          &lt;b class="boldest"&gt;
          Extremely bold
          &lt;/b&gt;
          ')
          tag = soup.b

          tag.name = "blockquote"
          tag['class'] = 'verybold'
          tag['id'] = 1
          tag
          #
          &lt;blockquote class="verybold" id="1"&gt;
          Extremely bold
          &lt;/blockquote&gt;
          del tag['class']
          del tag['id']
          tag
          #
          &lt;blockquote&gt;
          Extremely bold
          &lt;/blockquote&gt;
          给tag的 .string 属性赋值,就相当于用当前的内容替代了原来的内容:
          Tag.append() 方法想tag中添加内容
          如果想添加一段文本内容到文档中也没问题,可以调用Python的 append() 方法 或调用 NavigableString 的构造方法

          如果想要创建一段注释
          from bs4 import Comment
          new_comment = soup.new_string("Nice to see you.", Comment)
          tag.append(new_comment)
          创建一个tag最好的方法是调用工厂方法 BeautifulSoup.new_tag() :
          new_tag = soup.new_tag("a", href="http://www.example.com")
          Tag.insert(),而是把元素插入到指定的位置
          insert_before() 和 insert_after()
          Tag.clear() 方法移除当前tag的内容:
          PageElement.extract() 方法将当前tag移除文档树,并作为方法结果返回:
          Tag.decompose() 方法将当前节点移除文档树并完全销毁:
          PageElement.replace_with() 方法移除文档树中的某段内容,并用新tag或文本节点替代它:
          PageElement.wrap() 方法可以对指定的tag元素进行包装 [8] ,并返回包装后的结果:
          Tag.unwrap() 方法将移除tag内的所有tag标签,该方法常被用来进行标记的解包:</code>

      输出
      <code>
          prettify() 方法将Beautiful Soup的文档树格式化
          只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:
          str() 方法返回UTF-8编码的字符串,可以指定 编码 的设置.
          还可以调用 encode() 方法获得字节码或调用 decode() 方法获得Unicode.

          Beautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“&amp;lquot”:
          soup = BeautifulSoup("“Dammit!” he said.")
          unicode(soup)
          # u'
          &lt;html&gt;
          &lt;head&gt;
          &lt;/head&gt;
          &lt;body&gt;
          \u201cDammit!\u201d he said.
          &lt;/body&gt;
          &lt;/html&gt;
          '

          查看编码
          soup.original_encoding
          通过传入 from_encoding 参数来指定编码方式:
          soup = BeautifulSoup(markup, from_encoding="iso-8859-8")
          输出编码:
          soup.prettify("latin-1")
          soup.p.encode("latin-1")

          如果想判断两个对象是否严格的指向同一个对象可以通过 is 来判断
          print first_b is second_b


          copy.copy() 方法可以复制任意 Tag 或 NavigableString 对象

          SoupStrainer 类可以定义文档的某段内容,这样搜索文档时就不必先解析整篇文档,只会解析在 SoupStrainer 中定义过的文档.</code>


  </div>

</body>

<link   href="style/styles.css" rel="stylesheet">
<script src="js/script.js"></script>

</html>
